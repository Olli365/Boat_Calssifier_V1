{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import librosa\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yes_Boat = os.path.join('Y_N_Boat', 'y', 'y_CCC_139.20220626_084400.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_white_noise(signal, noise_factor):\n",
    "    noise = np.random.normal(0, signal.std(), signal.size)\n",
    "    augemented_signal = signal + noise *  noise_factor\n",
    "    return augemented_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch(signal, stretch_rate):\n",
    "    # Stretch the signal\n",
    "    stretched_signal = librosa.effects.time_stretch(signal, rate=stretch_rate)\n",
    "    \n",
    "    original_length = len(signal)\n",
    "    stretched_length = len(stretched_signal)\n",
    "    \n",
    "    if stretched_length > original_length:\n",
    "        # If the stretched signal is longer, clip it to the original length\n",
    "        return stretched_signal[:original_length]\n",
    "    elif stretched_length < original_length:\n",
    "        # If the stretched signal is shorter, pad it to the original length\n",
    "        padding = original_length - stretched_length\n",
    "        return np.pad(stretched_signal, (0, padding), 'constant', constant_values=(0, 0))\n",
    "    else:\n",
    "        # If the lengths are equal, return the stretched signal as is\n",
    "        return stretched_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_scale(signal, sr, num_semimtones):\n",
    "    return librosa.effects.pitch_shift(signal, sr=sr, n_steps=num_semimtones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness(signal, max_delta):\n",
    "    return tf.image.random_brightness(signal, max_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_gain(signal, min_gain_factor, max_gain_factor):\n",
    "    gain_factor = np.random.uniform(min_gain_factor, max_gain_factor)\n",
    "    return signal * gain_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "wav, sr = librosa.load(Yes_Boat)\n",
    "choice2 = tf.random.uniform(shape=[], minval=0, maxval=3, dtype=tf.int32)\n",
    "choice2 = 0\n",
    "if choice2 == 0:\n",
    "    aug_wav = add_white_noise(wav, 0.3)\n",
    "elif choice2 == 1:\n",
    "    aug_wav = time_stretch(wav, 1.3)\n",
    "elif choice2 == 2:\n",
    "    aug_wav = pitch_scale(wav, sr, 5)\n",
    "elif choice2 == 3:\n",
    "    aug_wav = random_gain(wav, 1, 2)\n",
    "aug_wav = librosa.resample(aug_wav, orig_sr=sr, target_sr=16000 )\n",
    "aug_wav = tf.convert_to_tensor(aug_wav)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "aug_wav = aug_wav[:48000]\n",
    "zero_padding = tf.zeros([48000] - tf.shape(aug_wav), dtype=tf.float32)\n",
    "wav = tf.concat([zero_padding, wav], 0)\n",
    "spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "spectrogram = tf.abs(spectrogram)\n",
    "spectrogram = tf.expand_dims(spectrogram, axis=-1)\n",
    "# Normalization\n",
    "mean = tf.math.reduce_mean(spectrogram)\n",
    "std = tf.math.reduce_std(spectrogram)\n",
    "spectrogram = (spectrogram - mean) / std\n",
    "choice = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "if choice != 0:\n",
    "        choice2 = tf.random.uniform(shape=[], minval=0, maxval=3, dtype=tf.int32)\n",
    "        if choice2 == 0:\n",
    "            spectrogram = brightness(spectrogram, 0.05)\n",
    "\n",
    "\n",
    "spectrogram,\n",
    "aug_wav\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(filename):\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(filename):\n",
    "    def _augment_py(filename):\n",
    "        # Decode filename if it's encoded as bytes in a numpy array\n",
    "        if isinstance(filename, np.ndarray) and filename.dtype.type is np.bytes_:\n",
    "            filename = filename.item().decode('utf-8')  # Convert numpy bytes to string\n",
    "        elif isinstance(filename, np.ndarray):\n",
    "            filename = filename.item()  # Assuming it's already a string within a numpy object array\n",
    "        \n",
    "        wav, sr = librosa.load(filename)\n",
    "        choice = np.random.randint(0, 4)\n",
    "        if choice == 0:\n",
    "            aug_wav = add_white_noise(wav, 0.3)\n",
    "        elif choice == 1:\n",
    "            aug_wav = time_stretch(wav, 1.3)\n",
    "        elif choice == 2:\n",
    "            aug_wav = pitch_scale(wav, sr, 5)\n",
    "        elif choice == 3:\n",
    "            aug_wav = random_gain(wav, 1, 2)\n",
    "        aug_wav = librosa.resample(aug_wav, orig_sr=sr, target_sr=16000)\n",
    "        return aug_wav.astype(np.float32)\n",
    "    \n",
    "    # Use tf.numpy_function with the correct signature - it expects the function, inputs, and output types\n",
    "    aug_wav = tf.numpy_function(_augment_py, [filename], tf.float32)\n",
    "    aug_wav.set_shape([None])  # Adjust this shape based on your data\n",
    "    return aug_wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = augment(Yes_Boat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = load_wav_16k_mono(Yes_Boat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path, label):\n",
    "    def _preprocess_py(file_path, label):\n",
    "        choice = np.random.randint(0, 4)\n",
    "        if choice == 0:\n",
    "            wav = augment(file_path)\n",
    "        else:\n",
    "            wav = load_wav_16k_mono(file_path)\n",
    "        wav = wav[:48000]\n",
    "        zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
    "        wav = tf.concat([zero_padding, wav], 0)\n",
    "        spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "        spectrogram = tf.abs(spectrogram)\n",
    "        spectrogram = tf.expand_dims(spectrogram, axis=-1)\n",
    "        # Normalization\n",
    "        mean = tf.math.reduce_mean(spectrogram)\n",
    "        std = tf.math.reduce_std(spectrogram)\n",
    "        spectrogram = (spectrogram - mean) / std\n",
    "        return spectrogram, label\n",
    "    return tf.numpy_function(_preprocess_py, [file_path, label], [tf.float32, tf.float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS = os.path.join('Y_N_Boat', 'y')\n",
    "NEG = os.path.join('Y_N_Boat', 'n')\n",
    "\n",
    "num_files = 250\n",
    "pos = tf.data.Dataset.list_files(POS + '/*.wav')\n",
    "neg = tf.data.Dataset.list_files(NEG + '/*.wav').take(num_files)\n",
    "\n",
    "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
    "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: preprocess(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "data = data.batch(16)\n",
    "data = data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(32)\n",
    "test = data.skip(32).take(14)\n",
    "samples, labels = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257, 1)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoint/YN.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=5, validation_data=test, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'], 'r')\n",
    "plt.plot(hist.history['val_loss'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Precision')\n",
    "plt.plot(hist.history['precision'], 'r')\n",
    "plt.plot(hist.history['val_precision'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Recall')\n",
    "plt.plot(hist.history['recall'], 'r')\n",
    "plt.plot(hist.history['val_recall'], 'b')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
